---
title: "《MySQL技术内幕-InnoDB存储引擎》阅读小记（一）"
date: 2018-09-05T23:26:06+08:00
slug: innodb-storage-engine-reading-1
---

[TOC]



# MySQL体系结构

![](https://media.chyroc.cn/img/mysql.png)

# InnoDB存储引擎

## 概述

* 从mysql 5.5 版本开始是默认引擎
* 第一个完整支持 ACID 事务的MySQL引擎
* 特点：行锁设计、支持MVCC、支持外键、提供一致性非锁定读、有效利用内存和CPU

## 体系架构

![](https://media.chyroc.cn/img/innodb.png)

### 后台线程

* innodb存储引擎是多线程模型，有多个不同的后台线程，负责处理不同的任务

* master thread：将缓冲池的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲（insert buffer）、UNDO页的回收

* io thread

  * innodb大量使用了AIO(async io)处理io请求，极大提高了数据库的性能
  * io thread的工作主要是负责这些io请求的回调处理
  * 1.0版本之前共有4个io thread：write，read，insert buffer，log
  * 1.0之后，rread和write thread分别增大到了4个
  * 1.0之后，可以分别使用innodb_read_io_threads和innodb_write_io_threads设置线程数

* purge thread

  * 事务提交后，锁使用的undolog可能不再需要，所以需要purge thread 回收已经使用并且分配的undo页

  * 1.1之前，purge操作在master thread内完成

  * 1.1之后，purge可以独立到单独的线程，减轻master thread工作，提高cpu利用率和提高性能

  * 添加下面的配置 开启独立的purge thread

  * ```ini
    [mysqld]
    innodb_purge_threads=1
    ```

  * 1.1只支持设置innodb_purge_threads=1，1.1之后才支持设置多个

* page cleaner thread

  * 1.2.x版本引入
  * 将之前版本的脏页的刷新操作都放入单独的线程中
  * 减轻master thread的工作和对用户查询线程的阻塞，提高性能

### 内存

#### 缓冲池

innodb是基础磁盘存储的，将记录按照页的方式进行管理，是基础磁盘的数据库系统（disk-base database）

所以用缓冲池技术提高数据库的整体性能

* 读
  * 读取页的时候，将磁盘的页放在缓冲池中，这个过程称之为将也`FIX`在缓冲池中
  * 然后下一次读相同的页的时候，首先判断是不是在缓冲池里面
  * 是的话，直接读取该页，否则读磁盘
* 写
  * 先修改缓冲池中的页
  * 然后以一定的频率刷新到磁盘
  * 注意不是每次数据修改都刷新，而是通过`Checkpoint` 机制刷新会磁盘

所以缓冲池的大小影响数据库的整体性能

* 32为操作系统限制，只能设置为3G；可以打开PAE选项获得最大64G的内存
* 建议数据库系统都采用64位操作系统
* 可以通过配置innodb_bufer_pool_size设置

innodb内存数据对象

![](https://media.chyroc.cn/img/innodb-memory.png)

从1.0.x开始，可以有多个缓冲池实例，每个页根据哈希值平均分配到不同的缓冲池实例，可以通过innodb_buffer_pool_instances设置，默认为1

#### LRU list / Free list / Flush list

缓冲池通过LRU（lastest recent used ， 最近最少使用）算法进行管理：最先释放最不经常使用的数据

innodb对lru算法进行了一个优化：将新数据不放在首部，而是中间部位midpoint位置：扫描的时候读了一次数据就再也不用了，避免热点数据排除lru list。

这个算法叫做midpoint insertion strategy，midpoint位置由参数innodb_old_blocks_pct控制，默认是lru list的5/8处。

midpoint之后的list叫做old list，之前的list叫做new list。

## Checkpoint技术

做的什么事情

* 将缓冲池的脏页刷回到磁盘
* 重点在于：每次刷新多少页到磁盘，每次从哪里取脏数据，什么时间触发checkpoint

解决下面几个问题

* 缩短数据库的恢复时间：checkpoint之前的数据都已经刷到磁盘，只需要回复checkpoint之后的数据
* 缓冲池不够用的时候，将脏页刷新到磁盘：将lru算法溢出的数据，如果是脏页，刷回磁盘
* 重做日志不可用的时候，刷新脏页：？？？

innodb存储引擎使用LSN（log sequence number）标记版本，是一个8字节的数字，单位是字节。

每个页有LSN，重做日志也有LSN，checkpoint也有LSN

checkpoint发生的时间、条件、脏页的选择等都非常复杂

innodb内部有两种checkpoint

* sharp checkpoint：数据库关闭的时候将所有的脏页刷回到磁盘，默认方式，参数innodb_fast_shudown=1

* fuzzy checkpoint

  * master thread checkpoint：master thread异步的以每秒或者每10秒的速度从缓冲池的脏页列表中刷新一定比列的也回磁盘
  * flush_lru_list checkpoint：innodb需要保证lru list中有100个空闲页可使用，如果没有这么多，就会将lru list尾部的页移除。如果这些页有脏页，就需要进行checkpoint（在1.2.x开始，这些在一个单独的page cleaner线程中）
  * async/sync flush checkpoint：？？？
  * dirty page too much checkpoint：脏页太多，导致innodb强制进行checkpoint，为了保证缓冲池有足够的页。由innodb_max_dirty_pages_pct控制，假设为75（1.0.x之后的默认值），那么缓冲池中脏页数据占据75%的时候，就会强制checkpoint。



## master thread工作方式

主要工作都是在这里完成的

### innodb 1.0.x之间版本的master thread

Master thread内部有多个循环loop组成：

* 主循环 loop
* 后台循环 backgroup loop
* 刷新循环 flush loop
* 暂停循环 suspend loop

#### 主循环 loop

在主循环里面会有一个每秒进行的操作和一个每10秒进行的操作

每秒进行的操作：

* 日志缓冲刷新到磁盘，即使事务还没有提交（总是）：所以再大的事务提交也很快
* 合并插入缓冲（insert buffer）（可能）：判断前一秒发生的IO次数，如果小于5，认为当前IO压力很小，可以执行本操作
* 之多刷新100个innodb的缓冲池的脏页到磁盘（可能）：判断当前缓冲池里面的脏页的比例是否超过了配置值（默认90，90%），超过了阈值，就会将100个在脏页数据写入磁盘
* 如果当前没有用户活动，切换到backgroup loop（可能)

每10秒进行的操作：

* 刷新100个脏页到磁盘（可能）：判断过去10秒发送的IO次数，如果小于200，认为压力比较小，执行本操作
* 合并至多5个插入缓冲（总是）：然后执行这个
* 将日志缓冲刷新到磁盘（总是）：然后执行这个
* 删除无用的undo页（总是）：执行full purge操作（每次最多尝试回收20个undo页）
* 刷新100个或者10个脏页到磁盘（总是）：如果脏页比例超过70%，就刷新100个，否则是10个脏页会磁盘

#### Backgroup loop

如果没有用户活动或者数据库关闭（shutdown）就会切换到这个线程

执行以下操作：

* 删除无用的undo页（总是）
* 合并20个插入缓冲（总是）
* 跳回到主循环（总是）
* 不断刷新100个页直到符合条件（可能，跳转到flush loop中完成，如果flush loop中也没什么可做的，就会切换到suspend loop，将master thread挂起，等待事件）

### Innodb 1.2.x之前版本的master thread

刷新数量不再硬编码，而是使用百分比控制

* 在合并插入缓冲的时候，合并插入缓冲的数量为innodb_io_capacity的5%
* 在从缓冲区刷新脏页的时候，刷新脏页的数量为innodb_io_capacity

当使用ssd之类的时候，就可以调高 innodb_io_capacity，知道符合磁盘IO的吞吐量

将 innodb_max_dirty_pages_pct 从 90 调整到 80

略

### innodb 1.2.x版本的master thread

略

## innodb的关键特性

包括

* 插入缓冲 insert buffer
* 两次写 double write
* 自适应哈希索引 adaptive hash index
* 异步io async io
* 刷新邻接页 flush neighbor page

### 缓冲插入 insert buffer

带给innodb的是性能的提升

#### 1. insert buffer

缓冲池里面有insert buffer，**物理页里面也有**

在innodb中，主键是唯一的标识符。插入的时候会寻找到主键的位置，然后插入。

所以如果主键是逐渐递增的，那么就是磁盘的顺序IO，速度很快。

但是在一个表不会只有一个主键，可能还有其他索引，那么在B+树的叶子节点上，就要寻找到第二个索引所在的位置进行插入，也就是随机IO。

为了优化这种随机IO，创建了insert buffer：先判断插入的索引页是不是在缓冲池，如果是，就插入到缓冲池；如果不是，就先放到一个insert buffer中。然后再以一定的频率和情况将insert buffer和所以也子节点merge。这个时候通常能够将多个插入合并到一个操作里面（因为在一个索引页），大大提高了非聚集索引插入的性能。

insert buffer的使用需要同时满足以下两个条件：

* 索引是辅助索引 secondary index
* 索引不是唯一 unique 的：如果是唯一的，就需要先读一遍（随机读）看看是不是已经存在，就会失去意义

insert buffer的问题

#### 2. change buffer

1.0.x引入了change buffer，可视为insert buffer的升级，可以对dml操作都进行缓冲，分别是：

* insert buffer
* delete buffer
* purge buffer

同样有**非唯一**的限制

对一个记录进行update操作有两个过程

* 将记录标记为删除：delete buffer
* 将记录真正删除：pruge buffer

提供innodb_change_buffering参数，用来控制开启哪种buffer

* inserts
* deletes
* purges
* changes：开启inserts和deletes
* all：都开启
* node：都不开启

#### 3. Insert buffer的内部实现

insert buffer是一个全局的放在共享空间的B+树

* 叶子节点
* 非叶子节点

？？？

#### 4. merge isnert buffer

什么时候将insert buffer的数据merge到辅助索引页

* 辅助索引页被读取到缓冲池的时候：读这页的时候，看看这页有没有数据在insert buffer，如果有的就写到辅助索引页
* insert buffer bitmap追踪到该辅助索引页已经没有可用空间的时候：insert buffer bitmap记录每个辅助索引页的可用空间，如果可用空间少于1/32页，那么就会强制把insert buffer的数据写到辅助索引页
* master thread：每秒、每10秒会进行merge insert buffer（不止一个页）？？？

### 两次写 double write

带给innodb的是数据页的可靠性

假如写输入到一个页中，写到一半，发生宕机（部分写失效 partial page write），导致页损坏，那么可能会导致数据丢失。这个是不能通过重做日志恢复，因为页本身已经损坏，重做日志（对页的物理操作）没有意义。

需要先通过页的副本还原该页，再使用重做日志，这个叫做doublewrite。

![](https://media.chyroc.cn/img/innodb-doublewrite.png)

？？？？？？

### 自适应哈希索引 adaptive hash index

哈希：一次就可以定位数据

B+树：取决于树的高度，生产环境一般是3-4层，所以需要查询3-4次

AHI（adaptive hash index）：观察到一个访问模式访问频繁，就会建立哈希索引

* 通过该模式访问了100次（模式：where x = ?）
* 页通过该模式访问了N次，其中N = 页的记录 * 1/16

### 异步IO async io



### 刷新邻接页 flush neighbor page

刷新一个脏页的时候，检测这个页所在的区（extent）的所有页，如果是脏页，就一起刷新。

所以可以利用AIO将多个io合并为一个io

问题

* 如果将一个页不怎么脏的写入了，那么之后又会很快变脏？
* 固态硬盘有很高的IOPS，是不是还需要？（1.2.x可以关闭本功能）

